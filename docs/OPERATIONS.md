# Zinses-Rechner è¿ç»´æ‰‹å†Œ

## ğŸ¯ è¿ç»´æ¦‚è§ˆ

æœ¬æ‰‹å†Œä¸º Zinses-Rechner ç³»ç»Ÿçš„æ—¥å¸¸è¿ç»´æä¾›è¯¦ç»†æŒ‡å¯¼ï¼ŒåŒ…æ‹¬ç›‘æ§ã€ç»´æŠ¤ã€æ•…éšœæ’æŸ¥å’Œåº”æ€¥å“åº”æµç¨‹ã€‚

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

### ç”Ÿäº§ç¯å¢ƒç»„ä»¶

```mermaid
graph TB
    subgraph "Cloudflare Edge"
        CDN[CDNç¼“å­˜]
        WAF[Webåº”ç”¨é˜²ç«å¢™]
        DDoS[DDoSé˜²æŠ¤]
    end
    
    subgraph "å‰ç«¯æœåŠ¡"
        Pages[Cloudflare Pages<br/>zinses-rechner.de]
        Assets[é™æ€èµ„æº<br/>JS/CSS/Images]
    end
    
    subgraph "åç«¯æœåŠ¡"
        Workers[Cloudflare Workers<br/>api.zinses-rechner.de]
        D1[D1 æ•°æ®åº“<br/>SQLite]
        KV[KVå­˜å‚¨<br/>ç¼“å­˜å±‚]
    end
    
    subgraph "ç›‘æ§ç³»ç»Ÿ"
        Analytics[Cloudflare Analytics]
        Logs[Workersæ—¥å¿—]
        Alerts[å‘Šè­¦ç³»ç»Ÿ]
    end
    
    CDN --> Pages
    WAF --> Workers
    Workers --> D1
    Workers --> KV
    Workers --> Logs
    Analytics --> Alerts
```

### å…³é”®æœåŠ¡æ¸…å•

| æœåŠ¡ | ç±»å‹ | åŸŸå | çŠ¶æ€æ£€æŸ¥ |
|------|------|------|----------|
| å‰ç«¯åº”ç”¨ | Cloudflare Pages | zinses-rechner.de | `curl -I https://zinses-rechner.de` |
| APIæœåŠ¡ | Cloudflare Workers | api.zinses-rechner.de | `curl https://api.zinses-rechner.de/health` |
| æ•°æ®åº“ | Cloudflare D1 | - | `npx wrangler d1 info zinses-rechner-prod` |
| ç¼“å­˜ | Cloudflare KV | - | APIå¥åº·æ£€æŸ¥åŒ…å« |
| ç›‘æ§ | Cloudflare Analytics | - | Dashboardæ£€æŸ¥ |

## ğŸ“Š æ—¥å¸¸ç›‘æ§ä»»åŠ¡

### æ¯æ—¥æ£€æŸ¥æ¸…å• (5åˆ†é’Ÿ)

```bash
#!/bin/bash
# scripts/daily-health-check.sh

echo "ğŸ” å¼€å§‹æ¯æ—¥å¥åº·æ£€æŸ¥..."

# 1. å‰ç«¯æœåŠ¡æ£€æŸ¥
echo "æ£€æŸ¥å‰ç«¯æœåŠ¡..."
FRONTEND_STATUS=$(curl -s -o /dev/null -w "%{http_code}" https://zinses-rechner.de)
if [ "$FRONTEND_STATUS" = "200" ]; then
    echo "âœ… å‰ç«¯æœåŠ¡æ­£å¸¸"
else
    echo "âŒ å‰ç«¯æœåŠ¡å¼‚å¸¸: HTTP $FRONTEND_STATUS"
    # å‘é€å‘Šè­¦
    ./scripts/send-alert.sh "å‰ç«¯æœåŠ¡å¼‚å¸¸" "HTTPçŠ¶æ€ç : $FRONTEND_STATUS"
fi

# 2. APIæœåŠ¡æ£€æŸ¥
echo "æ£€æŸ¥APIæœåŠ¡..."
API_RESPONSE=$(curl -s https://api.zinses-rechner.de/health)
API_STATUS=$(echo $API_RESPONSE | jq -r '.status // "error"')
if [ "$API_STATUS" = "healthy" ]; then
    echo "âœ… APIæœåŠ¡æ­£å¸¸"
else
    echo "âŒ APIæœåŠ¡å¼‚å¸¸: $API_STATUS"
    ./scripts/send-alert.sh "APIæœåŠ¡å¼‚å¸¸" "çŠ¶æ€: $API_STATUS"
fi

# 3. æ•°æ®åº“è¿æ¥æ£€æŸ¥
echo "æ£€æŸ¥æ•°æ®åº“è¿æ¥..."
DB_CHECK=$(npx wrangler d1 execute zinses-rechner-prod --env production --command="SELECT 1 as test" 2>&1)
if echo "$DB_CHECK" | grep -q "test"; then
    echo "âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸"
else
    echo "âŒ æ•°æ®åº“è¿æ¥å¼‚å¸¸"
    ./scripts/send-alert.sh "æ•°æ®åº“è¿æ¥å¼‚å¸¸" "é”™è¯¯: $DB_CHECK"
fi

# 4. æ€§èƒ½æŒ‡æ ‡æ£€æŸ¥
echo "æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡..."
RESPONSE_TIME=$(curl -w "%{time_total}" -s -o /dev/null https://api.zinses-rechner.de/api/v1/calculate/compound-interest \
    -X POST -H "Content-Type: application/json" \
    -d '{"principal": 10000, "annual_rate": 4, "years": 10}')

if (( $(echo "$RESPONSE_TIME < 1.0" | bc -l) )); then
    echo "âœ… APIå“åº”æ—¶é—´æ­£å¸¸: ${RESPONSE_TIME}s"
else
    echo "âš ï¸ APIå“åº”æ—¶é—´è¾ƒæ…¢: ${RESPONSE_TIME}s"
    ./scripts/send-alert.sh "APIå“åº”æ—¶é—´è¿‡æ…¢" "å“åº”æ—¶é—´: ${RESPONSE_TIME}s"
fi

echo "âœ… æ¯æ—¥å¥åº·æ£€æŸ¥å®Œæˆ"
```

### æ¯å‘¨æ£€æŸ¥æ¸…å• (30åˆ†é’Ÿ)

```markdown
## æ¯å‘¨è¿ç»´æ£€æŸ¥æ¸…å•

### ç³»ç»Ÿæ€§èƒ½å®¡æŸ¥
- [ ] æ£€æŸ¥è¿‡å»7å¤©çš„å“åº”æ—¶é—´è¶‹åŠ¿
- [ ] åˆ†æé”™è¯¯æ—¥å¿—å’Œå¼‚å¸¸æ¨¡å¼
- [ ] éªŒè¯ç¼“å­˜å‘½ä¸­ç‡ (ç›®æ ‡: >85%)
- [ ] æ£€æŸ¥èµ„æºä½¿ç”¨ç‡è¶‹åŠ¿

### å®‰å…¨çŠ¶æ€æ£€æŸ¥
- [ ] å®¡æŸ¥å®‰å…¨äº‹ä»¶æ—¥å¿—
- [ ] æ£€æŸ¥WAFè§„åˆ™è§¦å‘æƒ…å†µ
- [ ] éªŒè¯SSLè¯ä¹¦æœ‰æ•ˆæœŸ (>30å¤©)
- [ ] è¿è¡Œä¾èµ–æ¼æ´æ‰«æ

### æ•°æ®å’Œå¤‡ä»½
- [ ] éªŒè¯æ•°æ®åº“å¤‡ä»½å®Œæ•´æ€§
- [ ] æ£€æŸ¥æ•°æ®å¢é•¿è¶‹åŠ¿
- [ ] æ¸…ç†è¿‡æœŸæ—¥å¿—å’Œä¸´æ—¶æ–‡ä»¶
- [ ] éªŒè¯ç›‘æ§æ•°æ®æ”¶é›†

### ç”¨æˆ·ä½“éªŒ
- [ ] æ£€æŸ¥Core Web VitalsæŒ‡æ ‡
- [ ] åˆ†æç”¨æˆ·åé¦ˆå’Œæ”¯æŒè¯·æ±‚
- [ ] éªŒè¯ç§»åŠ¨ç«¯ä½“éªŒ
- [ ] æµ‹è¯•å…³é”®ç”¨æˆ·æµç¨‹
```

### æ¯æœˆæ£€æŸ¥æ¸…å• (2å°æ—¶)

```bash
#!/bin/bash
# scripts/monthly-maintenance.sh

echo "ğŸ”§ å¼€å§‹æ¯æœˆç»´æŠ¤ä»»åŠ¡..."

# 1. ä¾èµ–æ›´æ–°æ£€æŸ¥
echo "æ£€æŸ¥ä¾èµ–æ›´æ–°..."
cd zinses-rechner-frontend
npm audit
npm outdated

cd ../cloudflare-workers/api-worker
npm audit
npm outdated

# 2. å®‰å…¨æ‰«æ
echo "è¿è¡Œå®‰å…¨æ‰«æ..."
cd ../../security
./scripts/run-security-scan.sh full

# 3. æ€§èƒ½åŸºå‡†æµ‹è¯•
echo "è¿è¡Œæ€§èƒ½æµ‹è¯•..."
cd ../scripts
./performance-benchmark.sh production

# 4. æ•°æ®åº“ç»´æŠ¤
echo "æ•°æ®åº“ç»´æŠ¤..."
npx wrangler d1 execute zinses-rechner-prod --env production \
    --command="DELETE FROM calculation_history WHERE created_at < datetime('now', '-90 days')"

# 5. ç›‘æ§é…ç½®å®¡æŸ¥
echo "å®¡æŸ¥ç›‘æ§é…ç½®..."
./monitoring/scripts/review-monitoring-config.sh

# 6. ç”Ÿæˆæœˆåº¦æŠ¥å‘Š
echo "ç”Ÿæˆæœˆåº¦è¿ç»´æŠ¥å‘Š..."
./generate-monthly-report.sh

echo "âœ… æ¯æœˆç»´æŠ¤ä»»åŠ¡å®Œæˆ"
```

## ğŸš¨ æ•…éšœæ’æŸ¥æŒ‡å—

### ç´§æ€¥æ•…éšœå“åº”æµç¨‹

**ä¸¥é‡ç¨‹åº¦åˆ†çº§:**
- **P0 (Critical)**: æœåŠ¡å®Œå…¨ä¸å¯ç”¨ - 15åˆ†é’Ÿå†…å“åº”
- **P1 (High)**: æ ¸å¿ƒåŠŸèƒ½å—å½±å“ - 2å°æ—¶å†…å“åº”  
- **P2 (Medium)**: éƒ¨åˆ†åŠŸèƒ½å¼‚å¸¸ - 8å°æ—¶å†…å“åº”
- **P3 (Low)**: è½»å¾®é—®é¢˜ - 24å°æ—¶å†…å“åº”

**P0ç´§æ€¥å“åº”æµç¨‹:**
```bash
#!/bin/bash
# scripts/emergency-response.sh

echo "ğŸš¨ å¯åŠ¨ç´§æ€¥å“åº”æµç¨‹..."

# 1. ç«‹å³è¯Šæ–­
echo "1. å¿«é€Ÿè¯Šæ–­..."
curl -I https://zinses-rechner.de
curl -I https://api.zinses-rechner.de/health

# 2. æ£€æŸ¥CloudflareçŠ¶æ€
echo "2. æ£€æŸ¥CloudflareçŠ¶æ€..."
curl -s https://www.cloudflarestatus.com/api/v2/status.json | jq '.status.description'

# 3. æŸ¥çœ‹æœ€è¿‘éƒ¨ç½²
echo "3. æ£€æŸ¥æœ€è¿‘éƒ¨ç½²..."
git log --oneline -5

# 4. æ£€æŸ¥Workersæ—¥å¿—
echo "4. æ£€æŸ¥Workersæ—¥å¿—..."
npx wrangler tail --env production --format=pretty | head -20

# 5. è¯„ä¼°å›æ»šéœ€è¦
echo "5. è¯„ä¼°æ˜¯å¦éœ€è¦å›æ»š..."
read -p "æ˜¯å¦éœ€è¦ç«‹å³å›æ»š? (y/n): " rollback
if [ "$rollback" = "y" ]; then
    echo "æ‰§è¡Œç´§æ€¥å›æ»š..."
    npx wrangler rollback --env production
    echo "âœ… å›æ»šå®Œæˆï¼ŒéªŒè¯æœåŠ¡çŠ¶æ€..."
    sleep 30
    curl https://api.zinses-rechner.de/health
fi

# 6. é€šçŸ¥å›¢é˜Ÿ
echo "6. å‘é€ç´§æ€¥é€šçŸ¥..."
./scripts/send-emergency-alert.sh "P0æ•…éšœ" "æœåŠ¡ä¸å¯ç”¨ï¼Œæ­£åœ¨å¤„ç†"

echo "ğŸš¨ ç´§æ€¥å“åº”æµç¨‹å®Œæˆ"
```

### å¸¸è§æ•…éšœè¯Šæ–­

#### 1. APIå“åº”æ—¶é—´è¿‡é•¿

**ç—‡çŠ¶è¯†åˆ«:**
```bash
# æµ‹è¯•APIå“åº”æ—¶é—´
curl -w "@curl-format.txt" -o /dev/null -s \
    -X POST https://api.zinses-rechner.de/api/v1/calculate/compound-interest \
    -H "Content-Type: application/json" \
    -d '{"principal": 10000, "annual_rate": 4, "years": 10}'

# curl-format.txtå†…å®¹:
#      time_namelookup:  %{time_namelookup}\n
#         time_connect:  %{time_connect}\n
#      time_appconnect:  %{time_appconnect}\n
#     time_pretransfer:  %{time_pretransfer}\n
#        time_redirect:  %{time_redirect}\n
#   time_starttransfer:  %{time_starttransfer}\n
#                      ----------\n
#           time_total:  %{time_total}\n
```

**è¯Šæ–­æ­¥éª¤:**
```bash
# 1. æ£€æŸ¥Workersæ€§èƒ½
npx wrangler tail --env production | grep -E "(duration|error|timeout)"

# 2. æ£€æŸ¥æ•°æ®åº“æ€§èƒ½
npx wrangler d1 execute zinses-rechner-prod --env production \
    --command="SELECT COUNT(*) FROM calculation_history WHERE created_at > datetime('now', '-1 hour')"

# 3. æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
curl https://api.zinses-rechner.de/api/v1/monitoring/cache-stats

# 4. åˆ†ææ…¢æŸ¥è¯¢
./scripts/analyze-slow-queries.sh --hours=1
```

**è§£å†³æ–¹æ¡ˆ:**
1. **ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢**: æ·»åŠ ç´¢å¼•ï¼Œä¼˜åŒ–SQL
2. **å¢å¼ºç¼“å­˜ç­–ç•¥**: å»¶é•¿ç¼“å­˜æ—¶é—´ï¼Œé¢„çƒ­çƒ­ç‚¹æ•°æ®
3. **ä»£ç ä¼˜åŒ–**: å‡å°‘è®¡ç®—å¤æ‚åº¦ï¼Œå¼‚æ­¥å¤„ç†
4. **èµ„æºæ‰©å®¹**: è°ƒæ•´Workersé…ç½®

#### 2. å‰ç«¯é¡µé¢åŠ è½½ç¼“æ…¢

**è¯Šæ–­å·¥å…·:**
```bash
# 1. Lighthouseæ€§èƒ½åˆ†æ
npx lighthouse https://zinses-rechner.de \
    --output=json \
    --output-path=reports/lighthouse-$(date +%Y%m%d).json

# 2. åˆ†æå…³é”®æŒ‡æ ‡
jq '.categories.performance.score, .audits["largest-contentful-paint"].numericValue' \
    reports/lighthouse-$(date +%Y%m%d).json

# 3. æ£€æŸ¥èµ„æºåŠ è½½
curl -w "@curl-format.txt" -o /dev/null -s https://zinses-rechner.de

# 4. åˆ†æBundleå¤§å°
cd zinses-rechner-frontend
npm run build -- --analyze
```

**ä¼˜åŒ–æªæ–½:**
```typescript
// 1. ä»£ç åˆ†å‰²ä¼˜åŒ–
const Calculator = defineAsyncComponent(() => import('./views/Calculator.vue'))
const Charts = defineAsyncComponent(() => import('./components/Charts.vue'))

// 2. èµ„æºé¢„åŠ è½½
const preloadCriticalResources = () => {
    const link = document.createElement('link')
    link.rel = 'preload'
    link.href = '/api/v1/calculate/compound-interest'
    link.as = 'fetch'
    document.head.appendChild(link)
}

// 3. å›¾ç‰‡ä¼˜åŒ–
const getOptimizedImage = (src: string, width: number) => {
    return `https://imagedelivery.net/account/${src}/w=${width},f=webp`
}
```

#### 3. æ•°æ®åº“è¿æ¥é—®é¢˜

**è¯Šæ–­æ­¥éª¤:**
```bash
# 1. æ£€æŸ¥D1æ•°æ®åº“çŠ¶æ€
npx wrangler d1 info zinses-rechner-prod --env production

# 2. æµ‹è¯•æ•°æ®åº“è¿æ¥
npx wrangler d1 execute zinses-rechner-prod --env production \
    --command="SELECT 1 as test"

# 3. æ£€æŸ¥æ•°æ®åº“å¤§å°å’Œæ€§èƒ½
npx wrangler d1 execute zinses-rechner-prod --env production \
    --command="SELECT 
        COUNT(*) as total_records,
        MAX(created_at) as latest_record,
        MIN(created_at) as earliest_record
    FROM calculation_history"

# 4. åˆ†ææŸ¥è¯¢æ€§èƒ½
npx wrangler d1 execute zinses-rechner-prod --env production \
    --command="EXPLAIN QUERY PLAN 
    SELECT * FROM calculation_history 
    WHERE created_at > datetime('now', '-1 day')"
```

**è§£å†³æ–¹æ¡ˆ:**
```typescript
// è¿æ¥é‡è¯•æœºåˆ¶
export class DatabaseService {
    private async executeWithRetry<T>(
        operation: () => Promise<T>,
        maxRetries: number = 3
    ): Promise<T> {
        for (let attempt = 1; attempt <= maxRetries; attempt++) {
            try {
                return await operation()
            } catch (error) {
                if (attempt === maxRetries) throw error
                
                // æŒ‡æ•°é€€é¿
                const delay = Math.pow(2, attempt) * 1000
                await new Promise(resolve => setTimeout(resolve, delay))
            }
        }
        throw new Error('Max retries exceeded')
    }
}
```

## ğŸ”§ ç»´æŠ¤ä»»åŠ¡

### æ•°æ®åº“ç»´æŠ¤

**å®šæœŸæ¸…ç†ä»»åŠ¡:**
```bash
#!/bin/bash
# scripts/database-maintenance.sh

echo "ğŸ—„ï¸ å¼€å§‹æ•°æ®åº“ç»´æŠ¤..."

# 1. æ¸…ç†è¿‡æœŸæ•°æ® (ä¿ç•™90å¤©)
npx wrangler d1 execute zinses-rechner-prod --env production \
    --command="DELETE FROM calculation_history WHERE created_at < datetime('now', '-90 days')"

# 2. æ¸…ç†ç³»ç»ŸæŒ‡æ ‡ (ä¿ç•™30å¤©)
npx wrangler d1 execute zinses-rechner-prod --env production \
    --command="DELETE FROM system_metrics WHERE timestamp < datetime('now', '-30 days')"

# 3. é‡å»ºç´¢å¼•
npx wrangler d1 execute zinses-rechner-prod --env production \
    --command="REINDEX"

# 4. åˆ†æè¡¨ç»Ÿè®¡
npx wrangler d1 execute zinses-rechner-prod --env production \
    --command="ANALYZE"

# 5. æ£€æŸ¥æ•°æ®åº“å¤§å°
DB_SIZE=$(npx wrangler d1 info zinses-rechner-prod --env production | grep "Size" | awk '{print $2}')
echo "æ•°æ®åº“å¤§å°: $DB_SIZE"

if [ "${DB_SIZE%MB}" -gt 500 ]; then
    echo "âš ï¸ æ•°æ®åº“å¤§å°è¶…è¿‡500MBï¼Œè€ƒè™‘æ•°æ®å½’æ¡£"
    ./scripts/send-alert.sh "æ•°æ®åº“å¤§å°å‘Šè­¦" "å½“å‰å¤§å°: $DB_SIZE"
fi

echo "âœ… æ•°æ®åº“ç»´æŠ¤å®Œæˆ"
```

**æ•°æ®å¤‡ä»½ç­–ç•¥:**
```bash
#!/bin/bash
# scripts/backup-database.sh

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="backups/database"

mkdir -p "$BACKUP_DIR"

echo "ğŸ“¦ å¼€å§‹æ•°æ®åº“å¤‡ä»½..."

# å¯¼å‡ºç”Ÿäº§æ•°æ®åº“
npx wrangler d1 export zinses-rechner-prod --env production \
    --output "$BACKUP_DIR/zinses-rechner-prod-$TIMESTAMP.sql"

# å‹ç¼©å¤‡ä»½æ–‡ä»¶
gzip "$BACKUP_DIR/zinses-rechner-prod-$TIMESTAMP.sql"

# ä¸Šä¼ åˆ°äº‘å­˜å‚¨ (å¯é€‰)
if [ -n "$BACKUP_CLOUD_URL" ]; then
    aws s3 cp "$BACKUP_DIR/zinses-rechner-prod-$TIMESTAMP.sql.gz" \
        "$BACKUP_CLOUD_URL/database-backups/"
fi

# æ¸…ç†æ—§å¤‡ä»½ (ä¿ç•™30å¤©)
find "$BACKUP_DIR" -name "*.sql.gz" -mtime +30 -delete

echo "âœ… æ•°æ®åº“å¤‡ä»½å®Œæˆ: $BACKUP_DIR/zinses-rechner-prod-$TIMESTAMP.sql.gz"
```

### ç¼“å­˜ç®¡ç†

**ç¼“å­˜æ¸…ç†å’Œé¢„çƒ­:**
```bash
#!/bin/bash
# scripts/cache-management.sh

echo "ğŸ—‚ï¸ å¼€å§‹ç¼“å­˜ç®¡ç†..."

# 1. æ¸…ç†è¿‡æœŸç¼“å­˜
echo "æ¸…ç†è¿‡æœŸç¼“å­˜..."
npx wrangler kv:bulk delete --namespace-id="$KV_NAMESPACE_ID" \
    --preview=false \
    $(npx wrangler kv:key list --namespace-id="$KV_NAMESPACE_ID" | \
      jq -r '.[] | select(.expiration != null and (.expiration < now)) | .name')

# 2. é¢„çƒ­çƒ­ç‚¹æ•°æ®
echo "é¢„çƒ­çƒ­ç‚¹ç¼“å­˜..."
POPULAR_CALCULATIONS=(
    '{"principal": 10000, "annual_rate": 4, "years": 10}'
    '{"principal": 25000, "annual_rate": 5, "years": 15}'
    '{"principal": 50000, "annual_rate": 6, "years": 20}'
    '{"principal": 100000, "annual_rate": 4.5, "years": 25}'
)

for calc in "${POPULAR_CALCULATIONS[@]}"; do
    curl -s -X POST https://api.zinses-rechner.de/api/v1/calculate/compound-interest \
        -H "Content-Type: application/json" \
        -d "$calc" > /dev/null
    echo "é¢„çƒ­è®¡ç®—: $calc"
done

# 3. æ£€æŸ¥ç¼“å­˜ç»Ÿè®¡
CACHE_STATS=$(curl -s https://api.zinses-rechner.de/api/v1/monitoring/cache-stats)
HIT_RATE=$(echo $CACHE_STATS | jq -r '.hit_rate')

echo "ç¼“å­˜å‘½ä¸­ç‡: $HIT_RATE%"

if (( $(echo "$HIT_RATE < 80" | bc -l) )); then
    echo "âš ï¸ ç¼“å­˜å‘½ä¸­ç‡è¾ƒä½ï¼Œéœ€è¦ä¼˜åŒ–"
    ./scripts/send-alert.sh "ç¼“å­˜å‘½ä¸­ç‡ä½" "å½“å‰å‘½ä¸­ç‡: $HIT_RATE%"
fi

echo "âœ… ç¼“å­˜ç®¡ç†å®Œæˆ"
```

### æ—¥å¿—ç®¡ç†

**æ—¥å¿—æ”¶é›†å’Œåˆ†æ:**
```bash
#!/bin/bash
# scripts/log-analysis.sh

HOURS=${1:-24}
echo "ğŸ“‹ åˆ†ææœ€è¿‘ $HOURS å°æ—¶çš„æ—¥å¿—..."

# 1. æ”¶é›†Workersæ—¥å¿—
echo "æ”¶é›†Workersæ—¥å¿—..."
npx wrangler tail --env production --format=json \
    --since="${HOURS}h" > logs/workers-$(date +%Y%m%d).json

# 2. åˆ†æé”™è¯¯æ¨¡å¼
echo "åˆ†æé”™è¯¯æ¨¡å¼..."
cat logs/workers-$(date +%Y%m%d).json | \
    jq -r 'select(.level == "error") | .message' | \
    sort | uniq -c | sort -nr > logs/error-summary-$(date +%Y%m%d).txt

# 3. åˆ†ææ€§èƒ½æŒ‡æ ‡
echo "åˆ†ææ€§èƒ½æŒ‡æ ‡..."
cat logs/workers-$(date +%Y%m%d).json | \
    jq -r 'select(.duration_ms != null) | .duration_ms' | \
    awk '{sum+=$1; count++} END {print "å¹³å‡å“åº”æ—¶é—´:", sum/count "ms"}' \
    > logs/performance-summary-$(date +%Y%m%d).txt

# 4. æ£€æŸ¥å¼‚å¸¸IP
echo "æ£€æŸ¥å¼‚å¸¸IPæ´»åŠ¨..."
cat logs/workers-$(date +%Y%m%d).json | \
    jq -r '.client_ip' | sort | uniq -c | sort -nr | head -10 \
    > logs/top-ips-$(date +%Y%m%d).txt

# 5. ç”Ÿæˆæ—¥å¿—æŠ¥å‘Š
echo "ç”Ÿæˆæ—¥å¿—åˆ†ææŠ¥å‘Š..."
./scripts/generate-log-report.sh $HOURS

echo "âœ… æ—¥å¿—åˆ†æå®Œæˆï¼ŒæŠ¥å‘Šä¿å­˜åœ¨ logs/ ç›®å½•"
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### å‰ç«¯æ€§èƒ½ä¼˜åŒ–

**èµ„æºä¼˜åŒ–æ£€æŸ¥:**
```bash
#!/bin/bash
# scripts/frontend-optimization-check.sh

echo "âš¡ æ£€æŸ¥å‰ç«¯æ€§èƒ½ä¼˜åŒ–..."

cd zinses-rechner-frontend

# 1. åˆ†æBundleå¤§å°
echo "1. åˆ†æBundleå¤§å°..."
npm run build -- --analyze
BUNDLE_SIZE=$(du -sh dist/ | cut -f1)
echo "Bundleæ€»å¤§å°: $BUNDLE_SIZE"

# 2. æ£€æŸ¥æœªä½¿ç”¨çš„ä¾èµ–
echo "2. æ£€æŸ¥æœªä½¿ç”¨çš„ä¾èµ–..."
npx depcheck

# 3. æ£€æŸ¥é‡å¤ä¾èµ–
echo "3. æ£€æŸ¥é‡å¤ä¾èµ–..."
npx npm-check-duplicates

# 4. åˆ†æå…³é”®æ¸²æŸ“è·¯å¾„
echo "4. åˆ†æå…³é”®æ¸²æŸ“è·¯å¾„..."
npx lighthouse https://zinses-rechner.de \
    --only-categories=performance \
    --output=json \
    --output-path=../reports/performance-$(date +%Y%m%d).json

# 5. æ£€æŸ¥å›¾ç‰‡ä¼˜åŒ–
echo "5. æ£€æŸ¥å›¾ç‰‡ä¼˜åŒ–..."
find public/ -name "*.png" -o -name "*.jpg" -o -name "*.jpeg" | \
    xargs -I {} sh -c 'echo "{}:" $(du -h "{}")'

echo "âœ… å‰ç«¯æ€§èƒ½æ£€æŸ¥å®Œæˆ"
```

### åç«¯æ€§èƒ½ä¼˜åŒ–

**Workersæ€§èƒ½ç›‘æ§:**
```typescript
// workers/performance-monitor.ts
export class WorkersPerformanceMonitor {
    static async measureEndpointPerformance(
        endpoint: string,
        handler: (request: Request) => Promise<Response>
    ): Promise<PerformanceReport> {
        const startTime = Date.now()
        const startCPU = performance.now()
        
        try {
            const response = await handler(request)
            const endTime = Date.now()
            const endCPU = performance.now()
            
            return {
                endpoint,
                duration_ms: endTime - startTime,
                cpu_time_ms: endCPU - startCPU,
                status_code: response.status,
                response_size: response.headers.get('content-length') || '0',
                timestamp: new Date().toISOString()
            }
        } catch (error) {
            return {
                endpoint,
                duration_ms: Date.now() - startTime,
                cpu_time_ms: performance.now() - startCPU,
                status_code: 500,
                error: error.message,
                timestamp: new Date().toISOString()
            }
        }
    }
}
```

## ğŸ”’ å®‰å…¨è¿ç»´

### å®‰å…¨äº‹ä»¶å“åº”

**å®‰å…¨äº‹ä»¶åˆ†ç±»:**
```typescript
// security/incident-classifier.ts
export enum SecurityIncidentType {
    SQL_INJECTION = 'sql_injection',
    XSS_ATTEMPT = 'xss_attempt',
    BRUTE_FORCE = 'brute_force',
    DDoS_ATTACK = 'ddos_attack',
    SUSPICIOUS_ACTIVITY = 'suspicious_activity',
    DATA_BREACH = 'data_breach'
}

export enum IncidentSeverity {
    LOW = 'low',
    MEDIUM = 'medium',
    HIGH = 'high',
    CRITICAL = 'critical'
}

export interface SecurityIncident {
    id: string
    type: SecurityIncidentType
    severity: IncidentSeverity
    timestamp: string
    client_ip: string
    user_agent: string
    details: Record<string, any>
    status: 'open' | 'investigating' | 'resolved' | 'false_positive'
}
```

**è‡ªåŠ¨å“åº”æœºåˆ¶:**
```bash
#!/bin/bash
# scripts/security-incident-response.sh

INCIDENT_TYPE=$1
SEVERITY=$2
CLIENT_IP=$3

echo "ğŸ›¡ï¸ å¤„ç†å®‰å…¨äº‹ä»¶: $INCIDENT_TYPE (ä¸¥é‡ç¨‹åº¦: $SEVERITY)"

case $SEVERITY in
    "critical")
        echo "ğŸš¨ Criticaläº‹ä»¶ - ç«‹å³é˜»æ­¢IP"
        # åœ¨Cloudflareä¸­é˜»æ­¢IP
        curl -X POST "https://api.cloudflare.com/client/v4/zones/$ZONE_ID/firewall/access_rules/rules" \
            -H "Authorization: Bearer $CF_API_TOKEN" \
            -H "Content-Type: application/json" \
            -d "{
                \"mode\": \"block\",
                \"configuration\": {
                    \"target\": \"ip\",
                    \"value\": \"$CLIENT_IP\"
                },
                \"notes\": \"Auto-blocked due to $INCIDENT_TYPE\"
            }"
        
        # å‘é€ç´§æ€¥å‘Šè­¦
        ./scripts/send-emergency-alert.sh "Criticalå®‰å…¨äº‹ä»¶" "$INCIDENT_TYPE from $CLIENT_IP"
        ;;
        
    "high")
        echo "âš ï¸ Highäº‹ä»¶ - é™åˆ¶IPè®¿é—®"
        # å®æ–½é€Ÿç‡é™åˆ¶
        ./scripts/rate-limit-ip.sh "$CLIENT_IP" 3600 # 1å°æ—¶é™åˆ¶
        
        # å‘é€å‘Šè­¦
        ./scripts/send-alert.sh "Highå®‰å…¨äº‹ä»¶" "$INCIDENT_TYPE from $CLIENT_IP"
        ;;
        
    "medium"|"low")
        echo "ğŸ“ è®°å½•äº‹ä»¶ç”¨äºåˆ†æ"
        # è®°å½•åˆ°å®‰å…¨æ—¥å¿—
        echo "$(date -Iseconds) [$SEVERITY] $INCIDENT_TYPE from $CLIENT_IP" >> logs/security-events.log
        ;;
esac

echo "âœ… å®‰å…¨äº‹ä»¶å¤„ç†å®Œæˆ"
```

### å®šæœŸå®‰å…¨æ£€æŸ¥

**æ¯å‘¨å®‰å…¨å®¡æŸ¥:**
```bash
#!/bin/bash
# scripts/weekly-security-review.sh

echo "ğŸ” å¼€å§‹æ¯å‘¨å®‰å…¨å®¡æŸ¥..."

# 1. è¿è¡Œå®‰å…¨æ‰«æ
echo "1. è¿è¡ŒOWASP ZAPæ‰«æ..."
cd security
./scripts/run-security-scan.sh baseline

# 2. æ£€æŸ¥ä¾èµ–æ¼æ´
echo "2. æ£€æŸ¥ä¾èµ–æ¼æ´..."
cd ../zinses-rechner-frontend
npm audit --audit-level=high

cd ../cloudflare-workers/api-worker
npm audit --audit-level=high

# 3. åˆ†æå®‰å…¨äº‹ä»¶
echo "3. åˆ†æå®‰å…¨äº‹ä»¶..."
cd ../../
./scripts/analyze-security-events.sh --days=7

# 4. æ£€æŸ¥SSLè¯ä¹¦
echo "4. æ£€æŸ¥SSLè¯ä¹¦..."
SSL_EXPIRY=$(echo | openssl s_client -servername zinses-rechner.de -connect zinses-rechner.de:443 2>/dev/null | \
    openssl x509 -noout -dates | grep notAfter | cut -d= -f2)
echo "SSLè¯ä¹¦åˆ°æœŸæ—¶é—´: $SSL_EXPIRY"

# 5. éªŒè¯å®‰å…¨å¤´
echo "5. éªŒè¯å®‰å…¨å¤´..."
curl -I https://zinses-rechner.de | grep -E "(X-Frame-Options|X-Content-Type-Options|Strict-Transport-Security)"

# 6. ç”Ÿæˆå®‰å…¨æŠ¥å‘Š
echo "6. ç”Ÿæˆå®‰å…¨æŠ¥å‘Š..."
./scripts/generate-security-report.sh --weekly

echo "âœ… æ¯å‘¨å®‰å…¨å®¡æŸ¥å®Œæˆ"
```

## ğŸ“Š ç›‘æ§å’Œå‘Šè­¦

### å…³é”®æŒ‡æ ‡ç›‘æ§

**ç³»ç»Ÿå¥åº·æŒ‡æ ‡:**
```typescript
// monitoring/health-metrics.ts
export interface HealthMetrics {
    // æœåŠ¡å¯ç”¨æ€§
    uptime_percentage: number
    response_time_p95: number
    error_rate_percentage: number
    
    // ä¸šåŠ¡æŒ‡æ ‡
    calculations_per_hour: number
    unique_users_daily: number
    conversion_rate: number
    
    // æŠ€æœ¯æŒ‡æ ‡
    cache_hit_rate: number
    database_connections: number
    memory_usage_mb: number
    cpu_usage_percentage: number
}

export const healthThresholds = {
    uptime_percentage: { warning: 99.5, critical: 99.0 },
    response_time_p95: { warning: 1000, critical: 2000 },
    error_rate_percentage: { warning: 0.5, critical: 1.0 },
    cache_hit_rate: { warning: 80, critical: 70 },
    cpu_usage_percentage: { warning: 80, critical: 90 },
    memory_usage_mb: { warning: 100, critical: 120 }
}
```

**å‘Šè­¦è§„åˆ™é…ç½®:**
```yaml
# monitoring/alert-rules.yml
alert_rules:
  - name: "APIå“åº”æ—¶é—´è¿‡é«˜"
    metric: "response_time_p95"
    condition: "greater_than"
    threshold: 1000
    duration_minutes: 5
    severity: "warning"
    channels: ["slack", "email"]
    
  - name: "é”™è¯¯ç‡è¿‡é«˜"
    metric: "error_rate_percentage"
    condition: "greater_than"
    threshold: 1.0
    duration_minutes: 3
    severity: "critical"
    channels: ["slack", "email", "pagerduty"]
    
  - name: "æœåŠ¡ä¸å¯ç”¨"
    metric: "uptime_percentage"
    condition: "less_than"
    threshold: 99.0
    duration_minutes: 1
    severity: "critical"
    channels: ["slack", "email", "pagerduty"]
```

### å‘Šè­¦é€šçŸ¥é…ç½®

**Slacké›†æˆ:**
```bash
#!/bin/bash
# scripts/send-alert.sh

ALERT_TITLE=$1
ALERT_MESSAGE=$2
SEVERITY=${3:-"warning"}

# è®¾ç½®é¢œè‰²
case $SEVERITY in
    "critical") COLOR="danger" ;;
    "warning") COLOR="warning" ;;
    *) COLOR="good" ;;
esac

# å‘é€Slacké€šçŸ¥
curl -X POST "$SLACK_WEBHOOK_URL" \
    -H 'Content-type: application/json' \
    -d "{
        \"text\": \"ğŸš¨ $ALERT_TITLE\",
        \"attachments\": [{
            \"color\": \"$COLOR\",
            \"fields\": [
                {\"title\": \"æ¶ˆæ¯\", \"value\": \"$ALERT_MESSAGE\", \"short\": false},
                {\"title\": \"æ—¶é—´\", \"value\": \"$(date -Iseconds)\", \"short\": true},
                {\"title\": \"ç¯å¢ƒ\", \"value\": \"Production\", \"short\": true}
            ],
            \"actions\": [
                {\"type\": \"button\", \"text\": \"æŸ¥çœ‹ä»ªè¡¨ç›˜\", \"url\": \"https://monitoring.zinses-rechner.de\"},
                {\"type\": \"button\", \"text\": \"æŸ¥çœ‹æ—¥å¿—\", \"url\": \"https://dash.cloudflare.com\"}
            ]
        }]
    }"

# è®°å½•å‘Šè­¦å†å²
echo "$(date -Iseconds) [$SEVERITY] $ALERT_TITLE: $ALERT_MESSAGE" >> logs/alerts.log
```

## ğŸ”„ éƒ¨ç½²å’Œå›æ»š

### éƒ¨ç½²æµç¨‹

**æ ‡å‡†éƒ¨ç½²æµç¨‹:**
```bash
#!/bin/bash
# scripts/deploy-production.sh

echo "ğŸš€ å¼€å§‹ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²..."

# 1. é¢„éƒ¨ç½²æ£€æŸ¥
echo "1. é¢„éƒ¨ç½²æ£€æŸ¥..."
./scripts/pre-deployment-check.sh
if [ $? -ne 0 ]; then
    echo "âŒ é¢„éƒ¨ç½²æ£€æŸ¥å¤±è´¥ï¼Œåœæ­¢éƒ¨ç½²"
    exit 1
fi

# 2. å¤‡ä»½å½“å‰ç‰ˆæœ¬
echo "2. å¤‡ä»½å½“å‰ç‰ˆæœ¬..."
CURRENT_VERSION=$(git rev-parse HEAD)
echo $CURRENT_VERSION > backups/last-deployed-version.txt

# 3. éƒ¨ç½²API
echo "3. éƒ¨ç½²APIåˆ°Workers..."
cd cloudflare-workers/api-worker
npx wrangler deploy --env production

# 4. éƒ¨ç½²å‰ç«¯
echo "4. éƒ¨ç½²å‰ç«¯åˆ°Pages..."
cd ../../zinses-rechner-frontend
npm run build
npx wrangler pages deploy dist --project-name=zinses-rechner

# 5. éªŒè¯éƒ¨ç½²
echo "5. éªŒè¯éƒ¨ç½²..."
sleep 30 # ç­‰å¾…éƒ¨ç½²ç”Ÿæ•ˆ
./scripts/verify-deployment.sh production

if [ $? -eq 0 ]; then
    echo "âœ… éƒ¨ç½²æˆåŠŸ"
    ./scripts/send-alert.sh "éƒ¨ç½²æˆåŠŸ" "ç‰ˆæœ¬ $CURRENT_VERSION å·²æˆåŠŸéƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ" "good"
else
    echo "âŒ éƒ¨ç½²éªŒè¯å¤±è´¥ï¼Œè€ƒè™‘å›æ»š"
    ./scripts/send-alert.sh "éƒ¨ç½²éªŒè¯å¤±è´¥" "ç‰ˆæœ¬ $CURRENT_VERSION éƒ¨ç½²åéªŒè¯å¤±è´¥" "danger"
    exit 1
fi
```

**å¿«é€Ÿå›æ»šæµç¨‹:**
```bash
#!/bin/bash
# scripts/emergency-rollback.sh

echo "ğŸ”„ å¼€å§‹ç´§æ€¥å›æ»š..."

# 1. å›æ»šWorkers
echo "1. å›æ»šWorkers..."
npx wrangler rollback --env production

# 2. å›æ»šå‰ç«¯ (é€šè¿‡Git)
echo "2. å›æ»šå‰ç«¯..."
LAST_VERSION=$(cat backups/last-deployed-version.txt)
git checkout $LAST_VERSION
cd zinses-rechner-frontend
npm run build
npx wrangler pages deploy dist --project-name=zinses-rechner

# 3. éªŒè¯å›æ»š
echo "3. éªŒè¯å›æ»š..."
sleep 30
./scripts/verify-deployment.sh production

if [ $? -eq 0 ]; then
    echo "âœ… å›æ»šæˆåŠŸ"
    ./scripts/send-alert.sh "ç´§æ€¥å›æ»šæˆåŠŸ" "ç³»ç»Ÿå·²å›æ»šåˆ°ç‰ˆæœ¬ $LAST_VERSION" "good"
else
    echo "âŒ å›æ»šå¤±è´¥ï¼Œéœ€è¦æ‰‹åŠ¨å¹²é¢„"
    ./scripts/send-emergency-alert.sh "å›æ»šå¤±è´¥" "ç´§æ€¥å›æ»šå¤±è´¥ï¼Œéœ€è¦ç«‹å³äººå·¥å¹²é¢„"
fi
```

## ğŸ“‹ è¿ç»´æ£€æŸ¥æ¸…å•

### æ¯æ—¥è¿ç»´æ¸…å• (10åˆ†é’Ÿ)

```markdown
## æ¯æ—¥è¿ç»´æ£€æŸ¥æ¸…å•

### ç³»ç»Ÿå¥åº· (2åˆ†é’Ÿ)
- [ ] å‰ç«¯æœåŠ¡å¯è®¿é—® (zinses-rechner.de)
- [ ] APIæœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡
- [ ] æ•°æ®åº“è¿æ¥æ­£å¸¸
- [ ] æ— Criticalçº§åˆ«å‘Šè­¦

### æ€§èƒ½æŒ‡æ ‡ (3åˆ†é’Ÿ)
- [ ] APIå“åº”æ—¶é—´ < 500ms (P95)
- [ ] å‰ç«¯LCP < 2.5ç§’
- [ ] ç¼“å­˜å‘½ä¸­ç‡ > 85%
- [ ] é”™è¯¯ç‡ < 0.1%

### å®‰å…¨çŠ¶æ€ (2åˆ†é’Ÿ)
- [ ] æ— æ–°çš„å®‰å…¨å‘Šè­¦
- [ ] WAFè§„åˆ™æ­£å¸¸è¿è¡Œ
- [ ] SSLè¯ä¹¦æœ‰æ•ˆæœŸ > 30å¤©
- [ ] æ— å¼‚å¸¸IPæ´»åŠ¨

### ä¸šåŠ¡æŒ‡æ ‡ (3åˆ†é’Ÿ)
- [ ] è®¡ç®—æˆåŠŸç‡ > 99.9%
- [ ] ç”¨æˆ·æ´»è·ƒåº¦æ­£å¸¸
- [ ] æ— ç”¨æˆ·æŠ•è¯‰æˆ–é—®é¢˜æŠ¥å‘Š
- [ ] ç›‘æ§æ•°æ®æ”¶é›†æ­£å¸¸
```

### æ¯å‘¨è¿ç»´æ¸…å• (1å°æ—¶)

```markdown
## æ¯å‘¨è¿ç»´æ£€æŸ¥æ¸…å•

### æ€§èƒ½åˆ†æ (20åˆ†é’Ÿ)
- [ ] åˆ†æè¿‡å»7å¤©çš„æ€§èƒ½è¶‹åŠ¿
- [ ] æ£€æŸ¥Core Web Vitalså˜åŒ–
- [ ] åˆ†ææ…¢æŸ¥è¯¢å’Œæ€§èƒ½ç“¶é¢ˆ
- [ ] è¯„ä¼°ç¼“å­˜ç­–ç•¥æ•ˆæœ

### å®‰å…¨å®¡æŸ¥ (20åˆ†é’Ÿ)
- [ ] è¿è¡Œå®Œæ•´å®‰å…¨æ‰«æ
- [ ] åˆ†æå®‰å…¨äº‹ä»¶æ—¥å¿—
- [ ] æ£€æŸ¥ä¾èµ–æ¼æ´
- [ ] éªŒè¯å®‰å…¨é…ç½®

### æ•°æ®ç®¡ç† (10åˆ†é’Ÿ)
- [ ] éªŒè¯æ•°æ®åº“å¤‡ä»½
- [ ] æ¸…ç†è¿‡æœŸæ•°æ®
- [ ] æ£€æŸ¥æ•°æ®å¢é•¿è¶‹åŠ¿
- [ ] éªŒè¯æ•°æ®å®Œæ•´æ€§

### ç³»ç»Ÿç»´æŠ¤ (10åˆ†é’Ÿ)
- [ ] æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨
- [ ] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œæ—¥å¿—
- [ ] æ›´æ–°ç³»ç»Ÿæ–‡æ¡£
- [ ] è®¡åˆ’å¿…è¦çš„ç»´æŠ¤çª—å£
```

## ğŸ†˜ åº”æ€¥è”ç³»ä¿¡æ¯

### å›¢é˜Ÿè”ç³»æ–¹å¼

**æŠ€æœ¯å›¢é˜Ÿ:**
- **æŠ€æœ¯è´Ÿè´£äºº**: tech@zinses-rechner.de
- **è¿ç»´è´Ÿè´£äºº**: ops@zinses-rechner.de
- **å®‰å…¨è´Ÿè´£äºº**: security@zinses-rechner.de

**ç´§æ€¥è”ç³»:**
- **24/7çƒ­çº¿**: +49-xxx-xxx-xxxx
- **Slacké¢‘é“**: #zinses-rechner-alerts
- **PagerDuty**: zinses-rechner-oncall

### å¤–éƒ¨æœåŠ¡æ”¯æŒ

**Cloudflare:**
- **çŠ¶æ€é¡µé¢**: https://www.cloudflarestatus.com
- **æ”¯æŒæ–‡æ¡£**: https://developers.cloudflare.com
- **ä¼ä¸šæ”¯æŒ**: (å¦‚æœé€‚ç”¨)

**GitHub:**
- **çŠ¶æ€é¡µé¢**: https://www.githubstatus.com
- **æ”¯æŒæ–‡æ¡£**: https://docs.github.com

### å‡çº§è·¯å¾„

**äº‹ä»¶å‡çº§æµç¨‹:**
1. **L1 (è¿ç»´å·¥ç¨‹å¸ˆ)**: åˆå§‹å“åº”å’ŒåŸºç¡€è¯Šæ–­
2. **L2 (é«˜çº§å·¥ç¨‹å¸ˆ)**: æ·±åº¦æŠ€æœ¯åˆ†æå’Œä¿®å¤
3. **L3 (æ¶æ„å¸ˆ/CTO)**: æ¶æ„çº§é—®é¢˜å’Œé‡å¤§å†³ç­–
4. **å¤–éƒ¨ä¸“å®¶**: ç‰¹æ®Šæƒ…å†µä¸‹çš„ä¸“ä¸šæ”¯æŒ

## ğŸ“ˆ å®¹é‡è§„åˆ’

### èµ„æºä½¿ç”¨ç›‘æ§

**å½“å‰èµ„æºé™åˆ¶:**
- **Cloudflare Workers**: 100,000 requests/day (å…è´¹ç‰ˆ)
- **Cloudflare D1**: 5GB storage, 25M reads/month
- **Cloudflare KV**: 100,000 reads/day
- **Cloudflare Pages**: 500 builds/month

**æ‰©å®¹è§¦å‘æ¡ä»¶:**
- Workersè¯·æ±‚é‡ > 80,000/day
- D1å­˜å‚¨ä½¿ç”¨ > 4GB
- KVè¯»å–é‡ > 80,000/day
- å“åº”æ—¶é—´æŒç»­ > 1ç§’

**æ‰©å®¹è®¡åˆ’:**
```bash
#!/bin/bash
# scripts/capacity-planning.sh

echo "ğŸ“Š åˆ†æå®¹é‡ä½¿ç”¨æƒ…å†µ..."

# 1. æ£€æŸ¥Workersä½¿ç”¨é‡
WORKERS_USAGE=$(curl -s -H "Authorization: Bearer $CF_API_TOKEN" \
    "https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/workers/usage" | \
    jq -r '.result.requests.current')

echo "Workersè¯·æ±‚é‡: $WORKERS_USAGE"

# 2. æ£€æŸ¥D1ä½¿ç”¨é‡
D1_SIZE=$(npx wrangler d1 info zinses-rechner-prod --env production | \
    grep "Size" | awk '{print $2}' | sed 's/MB//')

echo "D1æ•°æ®åº“å¤§å°: ${D1_SIZE}MB"

# 3. é¢„æµ‹å¢é•¿
GROWTH_RATE=1.2 # 20%æœˆå¢é•¿
MONTHS_TO_LIMIT=$(echo "scale=1; (5000 - $D1_SIZE) / ($D1_SIZE * ($GROWTH_RATE - 1))" | bc)

echo "é¢„è®¡ $MONTHS_TO_LIMIT ä¸ªæœˆåè¾¾åˆ°D1å­˜å‚¨é™åˆ¶"

if (( $(echo "$MONTHS_TO_LIMIT < 3" | bc -l) )); then
    echo "âš ï¸ éœ€è¦è€ƒè™‘æ‰©å®¹æˆ–æ•°æ®å½’æ¡£"
    ./scripts/send-alert.sh "å®¹é‡å‘Šè­¦" "é¢„è®¡${MONTHS_TO_LIMIT}ä¸ªæœˆåè¾¾åˆ°å­˜å‚¨é™åˆ¶"
fi
```

---

*è¿ç»´æ‰‹å†Œç‰ˆæœ¬: 1.0.0 | æœ€åæ›´æ–°: 2024-01-15*
